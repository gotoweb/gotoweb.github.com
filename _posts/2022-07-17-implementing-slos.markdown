구글이 만든 SRE 책 중, [The Site Reliability Workbook](https://sre.google/workbook/table-of-contents/) 책은 아직 번역되지 않았는데, 프로메티우스 공부를 위해 이 책이 큰 도움이 된다는 사실을 알았습니다. 특히, [Chapter 2 - Implementing SLOs](https://sre.google/workbook/implementing-slos/) 의 일부분이 매우 유용하여, 필요하 부분만 번역해보았습니다. 중간중간 구글 번역의 힘을 빌려서 문체가 다를 수 있습니다.

또한, 프로메테우스 실습 과정을 추가적으로 첨부했습니다. _실습 n_ 으로 표시됩니다.

- - -

## 작동하는 예제

그림 2-1에 나온 것과 같이 모바일 게임을 위한 간단한 아키텍처를 생각해보자.

![그림2-1. 모바일 게임 아키텍처 예시](https://lh3.googleusercontent.com/ybtJ6StguyvFHIm7A2AlS3BcLKUy6DQCUHOHS-p0efcZcQvdY1ua1XXCZaKnPBcbekeulT72dIWWNNv3k1REJOTQS4KTWOjtbcx6IvA=s539)

_그림2-1. 모바일 게임 아키텍처 예시_

앱은 사용자의 폰에서 작동하며, HTTP API를 이용해 클라우드와 상호작용한다. API는 상태 변화를 영속적인 저장 공간에 기록한다. 이러한 데이터는 파이프라인을 통해 주기적으로 생성되며, 리그 테이블에 기록된다. 이 데이터는 오늘/이번 주/전체 하이스코어와 같은 자료를 제공하는 데 사용된다. 이 데이터는 별도의 리그 테이블 데이터 스토어에 기록되며, 이러한 결과는 모바일 앱의 인게임 스코어 또는 웹사이트에서 사용 가능하다. 사용자는 아바타를 사용자 데이터 테이블에 업로드할 수 있으며, 이는 인게임 또는 API를 통해 하이스코어 웹사이트에서 사용될 수 있다.

이러한 환경이 주어진다고 가정하고, 어떻게 사용자가 시스템과 인터랙션하는지에 대해서 생각해보자. 그리고 사용자 경험 차원에서 다양한 관점을 바탕으로 한 어떤 종류의 SLI를 측정할 수 있는지도 고려해보자.

몇몇 SLI는 오버랩될수 있다. 요청 기반 서비스는 정확성 SLI를 갖고 있을 수 있고, 파이프라인도 가용성 SLI을 가질 수 있다. 내구성 SLI는 정확성 SLI의 변형으로 볼 수 있다. 일단, 우리는 고객에게 중요한 기능을 대표하는 적은 수의 SLI 타입을 선택하는 것을 추천한다.

일반적인 사용자 경험과 롱테일을 모두 포착하기 위해 일부 유형의 SLI에 대해 여러 등급의 SLO를 사용하는 것이 좋습니다. 예를 들어 사용자 요청의 90%가 100ms 이내에 반환되지만 나머지 10%는 10초가 걸린다면 많은 사용자가 불만을 가질 것입니다. 대기 시간 SLO는 여러 임계값을 설정하여 이 사용자 기반을 캡처할 수 있습니다. 요청의 90%는 100ms보다 빠르며 요청의 99%는 400ms보다 빠릅니다. 이 원칙은 사용자의 불행을 측정하는 매개변수가 있는 모든 SLI에 적용됩니다.

| 서비스 타입 | SLI 타입 | 설명 |
| --- | --- | --- |
| 요청 기반 | 가용성(Availability) | 성공적인 응답으로 이어진 요청의 비율입니다. |
| 요청 기반 | 지연 시간(Latency) | 일부 임계값보다 빠른 요청의 비율입니다. |
| 요청 기반 | 품질(Quality) | 과부하가 걸리거나 백엔드를 사용할 수 없을 때 서비스가 정상적으로 저하되는 경우 저하되지 않은 상태에서 제공된 응답의 비율을 측정해야 합니다. 예를 들어 사용자 데이터 저장소를 사용할 수 없는 경우 게임은 계속 플레이할 수 있지만 일반 이미지를 사용합니다. |
| 파이프라인 | 신선도(Freshness) | 특정 시간 임계값보다 최근에 업데이트된 데이터의 비율입니다. 이상적으로 이 측정항목은 사용자가 데이터에 액세스한 횟수를 계산하므로 사용자 경험을 가장 정확하게 반영합니다. |
| 파이프라인 | 정확성(Correctness) | 올바른 값이 나오는 파이프라인으로 들어오는 레코드의 비율입니다. |
| 파이프라인 | 커버리지(Coverage) | 일괄 처리의 경우 일부 목표 데이터 양을 초과하여 처리한 작업의 비율입니다. 스트리밍 처리의 경우 일정 기간 내에 성공적으로 처리된 수신 레코드의 비율입니다. |
| 저장소 | 내구성(Durability) | 성공적으로 읽을 수 있는 기록된 레코드의 비율입니다. 내구성 SLI에 특히 주의하십시오. 사용자가 원하는 데이터는 저장된 데이터의 작은 부분일 수 있습니다. 예를 들어, 지난 10년 동안 10억 개의 레코드가 있지만 사용자가 오늘의 레코드만 원하는 경우(사용할 수 없음) 거의 모든 데이터를 읽을 수 있음에도 불구하고 사용자는 만족하지 못할 것입니다. |

## Moving from SLI Specification to SLI Implementation

이제 SLI 사양을 알았으므로 이를 구현하는 방법에 대해 생각해야 합니다.

우선, SLI의 경우 최소한의 엔지니어링 작업이 필요한 것을 선택하십시오. 웹 서버 로그같은 경우 즉시 사용할 수 있지만, 이에 반해 (JavaScript 등을 이용해 심는) 프로브를 설정하는 경우 보통 몇 주, 몇 달이 걸릴 수 있습니다. 이럴 때에는 그냥 로그를 사용하십시오.

SLI를 측정하려면 충분한 정보가 필요합니다. 가용성을 위해서는 성공/실패 상태가 필요합니다. 느린 요청의 경우 요청을 처리하는 데 걸리는 시간이 필요합니다. 이 정보를 기록하려면 웹 서버를 재구성해야 할 수도 있습니다. 클라우드 기반 서비스를 사용하는 경우 이 정보 중 일부는 모니터링 대시보드에서 이미 사용할 수 있습니다.

각각의 장단점이 있는 예제 아키텍처에 대한 SLI 구현을 위한 다양한 옵션이 있습니다. 다음 섹션에서는 시스템의 세 가지 유형의 구성 요소에 대한 SLI를 자세히 설명합니다.

### API 및 HTTP 서버의 가용성과 지연 시간

고려된 모든 SLI 구현에 대해 HTTP 상태 코드에 따라 응답 성공 여부를 결정합니다. 5XX 응답은 SLO에 대해 계산되고 다른 모든 요청은 성공한 것으로 간주됩니다. 가용성 SLI는 성공한 요청의 비율이고 지연 SLI는 정의된 임계값보다 빠른 요청의 비율입니다.

SLI는 구체적이고 측정 가능해야 합니다. [What to Measure: Using SLIs](https://sre.google/workbook/implementing-slos/#what-to-measure-using-slis)에 제공된 잠재적 후보 목록을 요약하기 위해 SLI는 다음 소스 중 하나 이상을 사용할 수 있습니다.

- 애플리케이션 서버 로그
- 로드 밸런서 모니터링
- 블랙박스 모니터링
- 클라이언트 측 수단

이 예제에서는 메트릭이 이미 사용 가능하고 애플리케이션 서버의 로그보다 사용자 경험에 더 가까운 SLI를 제공하기 때문에 로드 밸런서 모니터링을 사용합니다.

### 파이프라인의 신선도, 커버리지 및 정확성

(생략)

## SLI 측정하기

그림 2-2는 화이트박스 모니터링 시스템이 예제 애플리케이션의 다양한 구성 요소에서 메트릭을 수집하는 방법을 보여줍니다.

![그림2-2. 모니터링 시스템이 SLI 지표를 수집하는 방법](https://lh3.googleusercontent.com/D34OxtlssXakaRffC2jB4YMxm9wqCPw0lu9NFEn3PCiat2AIFra6cNJAWW8LlGUoli0PFpBPgN28_6zn0ryguR_9i1N9JsJWHSW1hOU=s802)

_그림2-2. 모니터링 시스템이 SLI 지표를 수집하는 방법_

모니터링 시스템의 메트릭을 사용하여 스타터 SLO를 계산하는 예를 살펴보겠습니다. 이 예에서는 가용성 및 대기 시간 메트릭을 사용하지만 다른 모든 잠재적 SLO에도 동일한 원칙이 적용됩니다. 시스템에서 사용하는 메트릭의 전체 목록은 [예제 SLO 문서](https://sre.google/workbook/slo-document/)를 참조하십시오. 모든 예제는 Prometheus 표기법을 사용합니다.

### 로드 밸런서 지표

응답 코드별 요청 (백엔드)

```graphql
http_requests_total{host="api", status="500"}
```

누적 히스토그램으로서의 총 지연 시간 - 각 버킷은 해당 시간보다 작거나 같은(less equal) 요청 수를 계산합니다.

```graphql
http_request_duration_seconds{host="api", le="0.1"}
http_request_duration_seconds{host="api", le="0.2"}
http_request_duration_seconds{host="api", le="0.4"}
```

일반적으로 히스토그램으로 근사하는 것보다 느린 요청을 계산하는 것이 좋습니다. 그러나 해당 정보를 사용할 수 없기 때문에 모니터링 시스템에서 제공하는 히스토그램을 사용합니다. 또 다른 접근 방식은 로드 밸런서 구성의 다양한 느린 임계값(예: 임계값 100ms 및 500ms)을 기반으로 명시적 느린 요청 수를 지정하는 것입니다. 이 전략은 더 정확한 숫자를 제공하지만 더 많은 구성이 필요하므로 임계값을 소급하여 변경하기가 더 어렵습니다.

### 💡 실습 1: 히스토그램 결과 확인

![](image/2022-07-17-practice-1.png)

위 결과를 해석해보면, 지연시간(s)이

- 0.5 미만으로 관측된 요청 12건
- 0.25 미만 12건
- 0.1 미만 11건
- 0.05 미만 10건
- 0.025 미만 10건
- 0.01 미만 9건
- 0.005 미만 8건

따라서 응답시간 별 지연시간 분포는 다음과 같다.

| 0.005 미만 | 8 |
| --- | --- |
| 0.005~0.01 | 1 |
| 0.01~0.025 | 1 |
| 0.025~0.05 | 0 |
| 0.05~0.1 | 1 |
| 0.1~0.25 | 1 |



### SLI 계산하기

이전 메트릭을 사용하여 표 2-2와 같이 이전 7일 동안의 현재 SLI를 계산할 수 있습니다.

가용성

```graphql
sum(rate(http_requests_total{host="api", status!~"5.."}[7d]))
/
sum(rate(http_requests_total{host="api"}[7d])
```

지연 시간

```graphql
histogram_quantile(0.9, rate(http_request_duration_seconds_bucket[7d]))

histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[7d]))
```

### 💡 실습 2: 백분위수 확인

레퍼런스 [https://godekdls.github.io/Prometheus/querying.functions/](https://godekdls.github.io/Prometheus/querying.functions/)

nginx 인그레스 컨트롤러로 몇번의 요청을 보내고 나면, 일정 주기(15초) 이후 메트릭이 수집된다.

![](image/2022-07-17-practice-2.png)

![](image/2022-07-17-practice-3.png)

```graphql
histogram_quantile(0.9,(rate(nginx_ingress_controller_request_duration_seconds_bucket{status="200"}[1d])))
```

위 쿼리의 결과는 `0.24494`며, 이는 지난 하루동안, 수집한 지연 시간에서 90번째 백분위수(percentile)를 의미한다.

즉, latency의 90%ile에 해당하는 값이 `0.24494`이다. 90%의 사용자는 최대 0.2초 정도까지 느릴 수 있다.

50%ile 일 경우, `0.00428` 초가 나온다. (중앙값)

10%ile의 경우, `0.000856` 초가 나온다, 지연 시간이 적은 상위 10%의 사용자의 결과다.

퍼센타일 참고자료

- [https://lightblog.tistory.com/90](https://lightblog.tistory.com/90)
- 100개의 값을 가진 어떤 자료의 20 백분위수는, 20번째로 작은 값임.
- 50 백분위수는 중앙값임


### Using the SLIs to Calculate Starter SLOs

이러한 SLI를 관리 가능한 숫자(예: 2개의 유효 가용성 또는 최대 50ms의 지연 시간)로 반올림하여 시작 SLO를 얻을 수 있습니다.

예를 들어, 4주 동안 API 지표는 다음을 보여줍니다.

- 총 요청: 3,663,253
- 총 성공한 요청: 3,557,865(97.123%)
- 90번째 백분위수 지연 시간: 432ms
- 99번째 백분위수 지연 시간: 891ms

다른 SLI에 대해 이 프로세스를 반복하고 표 2-3과 같이 API에 대해 SLO를 제안할 수 있습니다.

(표 2-3) API에 대한 SLO 제안

| SLO 종류 | 목표 |
| --- | --- |
| 가용성 | 97% |
| 지연 시간 | 90%의 요청 < 450ms |
| 지연 시간 | 99%의 요청 < 900ms |

[예제 SLO 문서](https://sre.google/workbook/slo-document/)는 SLO 문서의 전체 예제를 제공합니다. 이 문서에는 간결함을 위해 여기에서 생략한 SLI 구현이 포함되어 있습니다.

이 제안된 SLI를 기반으로 표 2-4와 같이 4주 동안의 오류 예산을 계산할 수 있습니다.

(표 2-4) 4주간의 에러 비용

| SLO | 허용된 실패 (건) |
| --- | --- |
| 97%의 가용성 | 109,897 |
| 90%의 요청이 450ms보다 빨라야 함 | 366,325 |
| 99%의 요청이 900ms보다 빨라야 함 | 36,632 |
